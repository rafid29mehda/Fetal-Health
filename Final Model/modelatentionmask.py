# -*- coding: utf-8 -*-
"""ModelAtentionMask.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mi76ErppawqvgPM7d-EHwzhKwPlhTKWi
"""

# Install necessary libraries
!pip install pytorch-tabnet
!pip install captum
!pip install optuna
!pip install imbalanced-learn
!pip install dask-expr
!pip install scikit-learn-contrib
!pip install lightgbm

# Data manipulation and analysis
import pandas as pd
import numpy as np

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Preprocessing and modeling
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Handling imbalanced data
from imblearn.over_sampling import ADASYN
from imblearn.under_sampling import TomekLinks

# Deep Learning Model
from pytorch_tabnet.tab_model import TabNetClassifier

# Explainable AI
import shap

# Hyperparameter Optimization
import optuna
from optuna import Trial

# Suppress warnings for cleaner output
import warnings
warnings.filterwarnings('ignore')

# For model saving and loading
import joblib

# Import torch for TabNet
import torch

# Additional imports for Permutation Regularization
import torch.nn as nn

# -------------------
# 3. Load and Preprocess the Dataset
# -------------------
# Load the dataset
data = pd.read_csv('/content/fetal_health.csv')  # Update the path as necessary

# Display the first five rows to verify
print("First five rows of the dataset:")
print(data.head())

# Check the shape of the dataset
print(f"\nDataset Shape: {data.shape}")

# Features to drop based on prior analysis
features_to_drop = [
    'fetal_movement',
    'histogram_width',
    'histogram_max',
    'mean_value_of_long_term_variability',
    'histogram_number_of_peaks',
    'light_decelerations',
    'histogram_tendency',
    'histogram_number_of_zeroes',
    'severe_decelerations',
    'baseline value',
    'histogram_min'
]

# Drop the specified features
data_dropped = data.drop(columns=features_to_drop)

# Verify the remaining features
print("\nFeatures after dropping less important ones:")
print(data_dropped.columns.tolist())

# Check the new shape of the dataset
print(f"\nNew Dataset Shape after dropping features: {data_dropped.shape}")

# Convert 'fetal_health' to integer
data_dropped['fetal_health'] = data_dropped['fetal_health'].astype(int)

# Mapping numerical classes to descriptive labels
health_mapping = {1: 'Normal', 2: 'Suspect', 3: 'Pathological'}
data_dropped['fetal_health_label'] = data_dropped['fetal_health'].map(health_mapping)

# Display the mapping
print("\nDataset with Mapped Labels:")
print(data_dropped[['fetal_health', 'fetal_health_label']].head())

# Features and target
X = data_dropped.drop(['fetal_health', 'fetal_health_label'], axis=1)
y = data_dropped['fetal_health']

# Initialize ADASYN with 'auto' strategy to resample all classes
adasyn = ADASYN(sampling_strategy='auto', random_state=42)

# Apply ADASYN to the dataset
X_adasyn, y_adasyn = adasyn.fit_resample(X, y)

# Initialize Tomek Links
tomek = TomekLinks()

# Apply Tomek Links to clean the dataset
X_resampled, y_resampled = tomek.fit_resample(X_adasyn, y_adasyn)

# Display the shape of the resampled dataset and class distribution
print(f"\nResampled X shape after ADASYN + Tomek Links: {X_resampled.shape}")
print(f"Resampled y distribution after ADASYN + Tomek Links:\n{y_resampled.value_counts()}")

# Visualize the resampled class distribution
plt.figure(figsize=(8, 6))
sns.countplot(x=y_resampled, palette='viridis')
plt.title('Class Distribution After ADASYN + Tomek Links')
plt.xlabel('Fetal Health')
plt.ylabel('Count')
plt.show()

# Split the resampled data (70% train, 30% test) with stratification
X_train, X_test, y_train, y_test = train_test_split(
    X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled
)

# Display the shapes of the training and testing sets
print(f"\nTraining set shape: {X_train.shape}")
print(f"Testing set shape: {X_test.shape}")

# Initialize the MinMaxScaler
scaler = MinMaxScaler()

# Fit the scaler on the training data and transform
X_train_scaled = scaler.fit_transform(X_train)

# Transform the testing data
X_test_scaled = scaler.transform(X_test)

# Convert the scaled arrays back to DataFrames for easier handling
X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)

# Verify scaling by checking min and max values
print("\nMin of Scaled Training Features (Should be 0):")
print(X_train_scaled.min())

print("\nMax of Scaled Training Features (Should be 1):")
print(X_train_scaled.max())

# Adjust the target values so they start from 0
y_train = y_train - 1
y_test = y_test - 1

# Display the adjusted target distributions
print("\nAdjusted y_train distribution:")
print(pd.Series(y_train).value_counts())

print("\nAdjusted y_test distribution:")
print(pd.Series(y_test).value_counts())

# Further split the training data into training and validation sets (80% train, 20% validation)
X_train_final, X_valid, y_train_final, y_valid = train_test_split(
    X_train_scaled, y_train, test_size=0.2, random_state=42, stratify=y_train
)

# Display the shapes of the final training and validation sets
print(f"\nFinal Training set shape: {X_train_final.shape}")
print(f"Validation set shape: {X_valid.shape}")

# Define the objective function for Optuna
def objective(trial: Trial):
    # Define the hyperparameter space
    n_d = trial.suggest_int('n_d', 32, 128)
    n_a = trial.suggest_int('n_a', 32, 128)
    n_steps = trial.suggest_int('n_steps', 3, 10)
    gamma = trial.suggest_float('gamma', 1.0, 2.0)
    lambda_sparse = trial.suggest_float('lambda_sparse', 1e-4, 1e-2, log=True)
    learning_rate = trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True)
    batch_size = trial.suggest_categorical('batch_size', [128, 256, 512])

    # Initialize TabNet with current hyperparameters
    tabnet = TabNetClassifier(
        n_d=n_d,
        n_a=n_a,
        n_steps=n_steps,
        gamma=gamma,
        lambda_sparse=lambda_sparse,
        optimizer_fn=torch.optim.Adam,
        optimizer_params=dict(lr=learning_rate),
        mask_type='sparsemax',
        verbose=0
    )

    # Train the model on the final training set
    tabnet.fit(
        X_train=X_train_final.values,
        y_train=y_train_final.values,
        eval_set=[(X_valid.values, y_valid.values)],
        eval_name=['valid'],
        eval_metric=['accuracy'],
        max_epochs=100,
        patience=20,
        batch_size=batch_size,
        virtual_batch_size=128,
        num_workers=0,
        drop_last=False
    )

    # Predict on the validation set
    y_pred = tabnet.predict(X_valid.values)
    accuracy = accuracy_score(y_valid, y_pred)

    return accuracy

# Create and optimize the Optuna study
study = optuna.create_study(direction='maximize', study_name='TabNet Hyperparameter Optimization')
study.optimize(objective, n_trials=50, timeout=3600)  # Adjust n_trials and timeout as needed

# Display the best hyperparameters and validation accuracy
print("Best Hyperparameters: ", study.best_params)
print("Best Validation Accuracy: ", study.best_value)

# -------------------
# Part 1: Data Augmentation Function
# -------------------

def augment_data(X, y, permutation_prob=0.1):
    """
    Augment the dataset by randomly permuting feature orders with a given probability.

    Parameters:
    - X (numpy.ndarray or pandas.DataFrame): Feature matrix.
    - y (numpy.ndarray or pandas.Series): Target vector.
    - permutation_prob (float): Probability of permuting each sample.

    Returns:
    - X_augmented (numpy.ndarray): Augmented feature matrix.
    - y_augmented (numpy.ndarray): Augmented target vector.
    """
    X_augmented = []
    y_augmented = []
    for sample, label in zip(X, y):
        if np.random.rand() < permutation_prob:
            perm = np.random.permutation(sample.shape[0])
            sample = sample[perm]
        X_augmented.append(sample)
        y_augmented.append(label)
    return np.array(X_augmented), np.array(y_augmented)

# -------------------
# Part 2: Apply Data Augmentation
# -------------------

# Set the permutation probability (e.g., 10% of the training samples will have permuted features)
permutation_probability = 0.1

# Apply the augmentation function to the final training set
X_train_augmented, y_train_augmented = augment_data(
    X_train_final.values,
    y_train_final.values,
    permutation_prob=permutation_probability
)

# Display the shape of the augmented dataset
print(f"Original Training Set Shape: {X_train_final.shape}")
print(f"Augmented Training Set Shape: {X_train_augmented.shape}")

# -------------------
# Part 3: Initialize and Train TabNet with Augmented Data
# -------------------

# Initialize the TabNetClassifier with the best hyperparameters from Optuna
perm_reg_tabnet = TabNetClassifier(
    input_dim=X_train_final.shape[1],    # Number of features
    output_dim=3,                        # Number of classes: Normal, Suspect, Pathological
    n_d=study.best_params['n_d'],
    n_a=study.best_params['n_a'],
    n_steps=study.best_params['n_steps'],
    gamma=study.best_params['gamma'],
    lambda_sparse=study.best_params['lambda_sparse'],
    optimizer_fn=torch.optim.Adam,
    optimizer_params={'lr': study.best_params['learning_rate']},
    mask_type='sparsemax',
    verbose=1,
    seed=42  # For reproducibility
)

# Train the model on the augmented training data
perm_reg_tabnet.fit(
    X_train=X_train_augmented,
    y_train=y_train_augmented,
    eval_set=[(X_valid.values, y_valid.values), (X_test_scaled.values, y_test.values)],
    eval_name=['train', 'valid'],
    eval_metric=['accuracy'],
    max_epochs=100,
    patience=20,
    batch_size=study.best_params['batch_size'],
    virtual_batch_size=128,
    num_workers=0,
    drop_last=False
)

# -------------------
# Part 4: Predict and Evaluate on the Test Set
# -------------------

# Predict on the test set
y_pred_perm_reg = perm_reg_tabnet.predict(X_test_scaled.values)

# Generate the Classification Report
print("\nPermutation Regularized TabNet Classification Report:")
print(classification_report(y_test, y_pred_perm_reg, target_names=['Normal', 'Suspect', 'Pathological']))

# Generate the Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred_perm_reg)

# Visualize the Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Normal', 'Suspect', 'Pathological'],
            yticklabels=['Normal', 'Suspect', 'Pathological'])
plt.title('Confusion Matrix for Permutation Regularized TabNet')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# -------------------
# Part 5: Compute Permutation Feature Importance
# -------------------

def permutation_feature_importance(model, X, y, metric=accuracy_score, n_repeats=5):
    """
    Compute permutation feature importance for a trained model.

    Parameters:
    - model (TabNetClassifier): Trained TabNet model.
    - X (pandas.DataFrame): Feature matrix.
    - y (numpy.ndarray or pandas.Series): True labels.
    - metric (function): Performance metric to evaluate (default: accuracy_score).
    - n_repeats (int): Number of times to permute a feature.

    Returns:
    - feature_importances (dict): Mapping of feature names to importance scores.
    """
    feature_importances = {}
    baseline = metric(y, model.predict(X.values))

    for col in X.columns:
        scores = []
        for _ in range(n_repeats):
            X_permuted = X.copy()
            X_permuted[col] = np.random.permutation(X_permuted[col].values)
            y_pred = model.predict(X_permuted.values)
            score = metric(y, y_pred)
            scores.append(score)
        # Importance is the drop in performance
        importance = baseline - np.mean(scores)
        feature_importances[col] = importance

    return feature_importances

# Compute permutation feature importance
feature_importances = permutation_feature_importance(
    model=perm_reg_tabnet,
    X=X_test_scaled,
    y=y_test,
    metric=accuracy_score,
    n_repeats=5
)

# Convert to DataFrame for visualization
importance_df = pd.DataFrame({
    'Feature': list(feature_importances.keys()),
    'Importance': list(feature_importances.values())
}).sort_values(by='Importance', ascending=False)

# Display feature importances
print("\nPermutation Feature Importance:")
display(importance_df)

# Plotting Feature Importances
plt.figure(figsize=(10, 8))
sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')
plt.title('Permutation Feature Importance (External)')
plt.xlabel('Decrease in Accuracy')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()













