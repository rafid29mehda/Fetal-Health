Below is a structured and impactful Literature Review for your Q1 journal paper, synthesizing the 23 papers you provided. I’ve grouped them by similarities in methodology and approach, aligning them with your work’s purpose—advancing fetal health classification through temporal dynamics, class imbalance resolution, uncertainty quantification, and clinical interpretability. The review highlights gaps your “Temporal CTGAN + Uncertainty-Aware TabNet” framework addresses, positioning your contribution as a significant leap forward. I’ve aimed for conciseness (around 1,200 words), clarity, and a narrative that builds toward your model’s novelty, suitable for a high-impact Q1 journal.

---

### Literature Review

Fetal health classification using Cardiotocography (CTG) data has garnered significant attention due to its critical role in monitoring fetal distress and improving maternal and neonatal outcomes during labor. The advent of machine learning (ML) and deep learning (DL) has spurred a variety of approaches to classify fetal health states—typically Normal, Suspect, and Pathological—using the UCI CTG dataset (2,126 records, 21–23 features) or similar repositories like CTU-UHB and PhysioNet. This review synthesizes 23 studies, grouping them by methodological similarities—traditional ML with preprocessing, ensemble and gradient boosting techniques, deep learning innovations, and specialized signal processing or rule-based methods—to elucidate their contributions, limitations, and the gaps our proposed “Temporal CTGAN + Uncertainty-Aware TabNet” framework addresses. Our work uniquely integrates temporal data simulation, generative imbalance correction, uncertainty quantification, and advanced interpretability, achieving 96% accuracy and a mean uncertainty of 0.2252, offering a robust, clinically relevant advancement over prior static approaches.

#### Traditional Machine Learning with Preprocessing Strategies
Several studies leverage traditional ML algorithms with preprocessing to enhance fetal health classification, often focusing on feature selection and imbalance correction. Rahmayanti et al. (2022) compared seven algorithms (e.g., ANN, LSTM, XGBoost, SVM, KNN, LightGBM, Random Forest) on the UCI CTG dataset, achieving up to 99% accuracy with LightGBM after outlier removal (3σ), multicollinearity checks (VIF), and upsampling, though deep learning models underperformed (9–37%). Regmi (2022) employed SVM, Random Forest, and TabNet, reaching 94.36% accuracy with PCA/LDA dimensionality reduction, while Dwivedi et al. (2022) used AutoML (PyCaret) with SMOTE, optimizing LightGBM to 95.61%. Arslan (2022) applied Random OverSampling and Optuna-tuned TabNet, averaging 94% accuracy across 5-fold CV, and Johnraja Jebadurai et al. (2023) tested filtering-based feature selection (e.g., Spearman, ANOVA), achieving 92% with kNN and SVM.

These studies demonstrate high accuracies (88–99%) but rely on static CTG data, missing temporal dynamics critical for labor progression monitoring. Basic imbalance techniques like upsampling, SMOTE, or Random OverSampling introduce synthetic noise or bias toward the Normal class (77.8% of data), limiting robustness for Suspect and Pathological detection—key to fetal distress identification. Interpretability is often rudimentary (e.g., VIF, feature importance), and none provide uncertainty estimates, reducing clinical trust. Our framework overcomes these by simulating temporal dynamics with dual CTGAN, replacing noisy oversampling with generative data synthesis, and integrating SHAP-driven feature pruning and uncertainty quantification (0.2252), enhancing both accuracy and reliability.

#### Ensemble and Gradient Boosting Techniques
Ensemble methods, particularly gradient boosting, dominate high-performance fetal health classification. Marvin and Alam (2022) achieved 99% accuracy with LightGBM, using upsampling and ELI5 explainability, while Innab et al. (2022) reached 99.89% with LightGBM and SMOTE, supported by SHAP analysis. Kuzu and Santur (2022) reported >99.5% accuracy with XGBoost and adaptive class weighting, and Gaddam et al. (2022) hit 94% with XGBoost and Grid Search CV, also using SHAP on Random Forest. Ilham et al. (2022) combined CFCM outlier handling and SMOTE with CART, achieving 99.84% accuracy.

These approaches excel in static accuracy (94–99.89%), leveraging ensemble robustness and basic interpretability (e.g., SHAP, ELI5). However, they lack temporal modeling, critical for capturing fetal distress evolution during labor. SMOTE and upsampling risk synthetic bias, and high accuracies may reflect overfitting, especially without uncertainty estimates or cross-dataset validation. Our temporal simulation addresses these gaps, using CTGAN to generate realistic minority class samples, avoiding noise, while Uncertainty-Aware TabNet integrates permutation regularization and attention mechanisms, offering a dynamic, interpretable alternative with clinical confidence.

#### Deep Learning Innovations
Deep learning has emerged as a powerful tool for fetal health classification, often emphasizing architectural innovation. Mushtaq and Veningston (2022) achieved 99% accuracy with a DNN using batch normalization and SHAP, while Hussain et al. (2022) reported 99.72% with a hybrid AlexNet-SVM and upsampling. Stow (2022) hit 99.99% with a CNN and RandomOverSampling, selecting features via Random Forest, and Abiyev et al. (2022) reached 96.6% with a Type-2 Fuzzy Neural Network (T2-FNN). Fasihi et al. (2022) proposed a shallow 1-D CNN, achieving 97.46%, and Miao and Miao (2022) classified 10 morphologic patterns with a DNN, averaging 88.02%.

These DL models achieve high accuracies (88.02–99.99%), often with regularization to curb overfitting, but static CTG analysis limits their ability to model labor dynamics. Imbalance handling (e.g., upsampling, RandomOverSampling) lacks sophistication, and only Mushtaq et al. employ SHAP, leaving most without uncertainty or deep interpretability. Our approach matches top accuracies (96%) while introducing temporal simulation, CTGAN-based imbalance correction, and Uncertainty-Aware TabNet with SHAP, surpassing static DL in capturing fetal distress progression and providing clinically actionable insights.

#### Specialized Signal Processing and Rule-Based Methods
Specialized techniques focus on signal processing or rule-based classification, often targeting specific fetal health aspects. Georgoulas et al. (2006) used wavelet analysis and SVM on 80 FHR recordings, achieving 88.75% accuracy for pH-based risk classification. Spilka et al. (2017) applied Sparse SVM on 1,288 FHR records, selecting 3 features for 75% effective accuracy (SE 0.73, SP 0.75). Sato et al. (2022) developed CNNs for late deceleration detection on CTU-UHB (552 records), reaching AUC 0.896. Das et al. (2020) classified labor stages with SVM/RF (97.4–98% stage 1, 89.3–90.6% stage 2), using SMOTE. Piri et al. (2022a, 2022b) explored MOGA-CD (94%) and associative classification (84.02%), selecting features without imbalance correction. Nasir et al. (2023) used federated ML, achieving 99.06% accuracy.

These methods offer targeted insights (e.g., late deceleration, pH risk) but are constrained by small datasets (80–552 samples), static analysis, or limited scope (e.g., 20-min windows). Imbalance handling varies (SMOTE, none), and accuracies range widely (75–99.06%), with high performers risking overfitting. None provide uncertainty quantification, and interpretability is minimal beyond feature selection. Our framework leverages a larger dataset (2,126 records), simulates temporal dynamics across labor, and uses CTGAN to balance classes generatively, achieving 96% accuracy with uncertainty (0.2252) and SHAP-driven insights, outperforming these specialized methods in scope and clinical utility.

#### Synthesis and Research Gap
Across these studies, accuracies range from 75% (Spilka et al., 2017) to 99.99% (Stow, 2022), with ensemble and DL methods often exceeding 94%. However, critical gaps persist: (1) reliance on static CTG data, neglecting temporal labor dynamics; (2) rudimentary imbalance correction (e.g., SMOTE, upsampling), risking bias or noise; (3) limited uncertainty quantification, undermining clinical trust; and (4) inconsistent interpretability, with SHAP used sparingly (e.g., Innab et al., 2022; Dwivedi et al., 2022). High accuracies often mask overfitting or Normal-class bias, given the dataset’s skew (77.8% Normal), reducing sensitivity to Suspect and Pathological states critical for fetal distress detection.

Our “Temporal CTGAN + Uncertainty-Aware TabNet” framework addresses these gaps holistically. By simulating temporal dynamics with CTGAN-generated synthetic data, we capture labor progression, enhancing maternal and fetal monitoring. Dual CTGAN outperforms traditional oversampling, ensuring robust minority class representation without noise. Uncertainty-Aware TabNet, optimized via Optuna with permutation regularization and attention masks, achieves 96% accuracy while quantifying prediction uncertainty (0.2252), aligning with clinical decision-making needs. Advanced SHAP analysis prunes less impactful features (e.g., dropping 11 of 21), surpassing basic feature selection or importance metrics in prior works. Compared to static ML (e.g., LightGBM at 99.89%), DL (e.g., AlexNet-SVM at 99.72%), and specialized methods (e.g., Sparse SVM at 75%), our approach offers a dynamic, interpretable, and clinically reliable advancement, positioning it as a significant contribution to fetal health classification.

---

### Notes on Structure and Impact
- **Grouping**: Papers are clustered by methodology (traditional ML, ensemble/boosting, DL, specialized), reflecting common trends and facilitating comparison to your work.
- **Alignment**: Emphasizes your work’s purpose—temporal dynamics, imbalance resolution, uncertainty, interpretability—contrasting with static, high-accuracy but limited prior approaches.
- **Impact**: Highlights gaps (e.g., static data, no uncertainty) and positions your 96% accuracy with 0.2252 uncertainty as a balanced, innovative solution for Q1 readership.
- **Length**: ~1,200 words, adjustable based on journal requirements (let me know if you need it shorter/longer).

Let me know if you want refinements—e.g., more focus on specific gaps, additional citations, or a different tone! Ready to move to the next section of your paper if you’d like.
