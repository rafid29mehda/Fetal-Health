# -*- coding: utf-8 -*-
"""CTGAN-Accuracy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vedR8seBnDcSoGl35ekr8SQ9Ya4YDaKW
"""

# Install required libraries (if needed)
!pip install lightgbm ctgan -q

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Load original and synthetic datasets
original_data_path = '/content/fetal_health.csv'  # Update the path
synthetic_data_path = '/content/111balanced_fetal_health_dataset.csv'  # Update the path

original_data = pd.read_csv(original_data_path)
synthetic_data = pd.read_csv(synthetic_data_path)

# Display basic information about the datasets
print("Original Dataset Shape:", original_data.shape)
print("Synthetic Dataset Shape:", synthetic_data.shape)
print("\nOriginal Dataset Head:")
print(original_data.head())
print("\nSynthetic Dataset Head:")
print(synthetic_data.head())

# Separate features and target variable
target_column = 'fetal_health'  # Update if the column name differs
X_original = original_data.drop(columns=[target_column])
y_original = original_data[target_column]

X_synthetic = synthetic_data.drop(columns=[target_column])
y_synthetic = synthetic_data[target_column]

# Standardize features
scaler = StandardScaler()
X_original_scaled = scaler.fit_transform(X_original)
X_synthetic_scaled = scaler.transform(X_synthetic)

# Split datasets into training and testing sets
X_orig_train, X_orig_test, y_orig_train, y_orig_test = train_test_split(
    X_original_scaled, y_original, test_size=0.2, random_state=42, stratify=y_original)

X_syn_train, X_syn_test, y_syn_train, y_syn_test = train_test_split(
    X_synthetic_scaled, y_synthetic, test_size=0.2, random_state=42, stratify=y_synthetic)

# Train Random Forest on Original Data
rf_orig = RandomForestClassifier(random_state=42)
rf_orig.fit(X_orig_train, y_orig_train)
y_rf_orig_pred = rf_orig.predict(X_orig_test)

# Train LightGBM on Original Data
lgbm_orig = LGBMClassifier(random_state=42)
lgbm_orig.fit(X_orig_train, y_orig_train)
y_lgbm_orig_pred = lgbm_orig.predict(X_orig_test)

# Evaluate Original Data Models
print("Random Forest - Original Data")
print(classification_report(y_orig_test, y_rf_orig_pred))

print("LightGBM - Original Data")
print(classification_report(y_orig_test, y_lgbm_orig_pred))

# Train Random Forest on Synthetic Data
rf_syn = RandomForestClassifier(random_state=42)
rf_syn.fit(X_syn_train, y_syn_train)
y_rf_syn_pred = rf_syn.predict(X_syn_test)

# Train LightGBM on Synthetic Data
lgbm_syn = LGBMClassifier(random_state=42)
lgbm_syn.fit(X_syn_train, y_syn_train)
y_lgbm_syn_pred = lgbm_syn.predict(X_syn_test)

# Evaluate Synthetic Data Models
print("Random Forest - Synthetic Data")
print(classification_report(y_syn_test, y_rf_syn_pred))

print("LightGBM - Synthetic Data")
print(classification_report(y_syn_test, y_lgbm_syn_pred))

import matplotlib.pyplot as plt
import seaborn as sns

# Example: Plot distribution of a feature in original and synthetic datasets
feature_name = 'baseline value'  # Replace with a feature name
plt.figure(figsize=(10, 5))
sns.kdeplot(original_data[feature_name], label="Original", shade=True)
sns.kdeplot(synthetic_data[feature_name], label="Synthetic", shade=True)
plt.title(f"Distribution Comparison: {feature_name}")
plt.legend()
plt.show()











